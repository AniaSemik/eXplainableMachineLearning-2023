# -*- coding: utf-8 -*-
"""AnnaSemik_HW2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zV-Sb0RQpXWZDuUkMDixDc8HXmtqmW0C

# Homework 2
"""

#! pip install shap dalex

from google.colab import drive
drive.mount('/content/drive')

import shap
import pickle
import xgboost
import sklearn
import numpy as np
import dalex as dx
import pandas as pd

import warnings
warnings.filterwarnings("ignore")

from sklearn import preprocessing
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split

p = "/content/drive/MyDrive/Colab Notebooks/XAI/"

"""1. For the selected data set, train at least two tree-based ensemble models (random forest, gbm, catboost or any other boosting)"""

lreg_model = pickle.load(open(p+"logistic_regression_model.sav", 'rb'))
#boosting_model = pickle.load(open(p+"boosting_model.sav", 'rb'))
boosting_model = xgboost.Booster()
boosting_model.load_model(p+"boosting_model.txt")
rf_model = pickle.load(open(p+"random_forest_model.sav", 'rb'))

"""2. for some selected observations (two or three) from the selected dataset, calculate predictions for models selected in point (1)"""

#load the same data as when training the model

X_train = pd.read_csv(p+"X_train.csv", index_col=0)
X_test = pd.read_csv(p+"X_train.csv", index_col=0)
y_train = pd.read_csv(p+"y_train.csv", index_col=0)
y_test = pd.read_csv(p+"y_test.csv", index_col=0)

obs = [X_train.iloc[3,], X_train.iloc[33,], X_train.iloc[222,]]
obs = [np.array(i).reshape(1,-1) for i in obs]
obs_preds_lreg = [lreg_model.predict(i) for i in obs]
#obs_preds_boosting = [boosting_model.predict(i) for i in obs]
obs_preds_boosting = [boosting_model.predict(xgboost.DMatrix(i)) for i in obs]
obs_preds_rf = [rf_model.predict(i) for i in obs]

"""3. for observations selected in (2), calculate the decomposition of model prediction using SHAP, Break Down or both (packages for python: `dalex`, `shap`)."""

classifier = lambda m, d: m.predict(d)
explainer_lreg = dx.Explainer(lreg_model, X_train, y_train, predict_function=classifier, label="lreg")
explainer_boosting = dx.Explainer(boosting_model, X_train, y_train, predict_function=classifier, label="boosting")
explainer_rf = dx.Explainer(rf_model, X_train, y_train, predict_function=classifier, label="rf")

explainer_lreg.model_performance()
#explainer_boosting.model_performance()

explainer_rf.model_performance()

shap_lreg = [explainer_lreg.predict_parts(o, type="shap", label='Linear regression, observation '+str(i)) for o,i in zip(obs, (3,33,222))]
#shap_boosting = [explainer_boosting.predict_parts(o, type="shap", label='observation'+str(o)) for o in obs]
shap_rf = [explainer_rf.predict_parts(o, type="shap", label='Random forest, observation '+str(i)) for o,i in zip(obs, (3,33,222))]

shap_lreg[0].plot(shap_lreg[1::])
#shap_boosting[0].plot(shap_boosting[1::])
shap_rf[0].plot(shap_rf[1::])

bd_lreg = [explainer_lreg.predict_parts(o, type="break_down", label='Linear regression, observation '+str(i)) for o,i in zip(obs, (3,33,222))]
#bd_boosting = [explainer_boosting.predict_parts(o, type="break_down", label='observation'+str(o)) for o in obs]
bd_rf = [explainer_rf.predict_parts(o, type="break_down", label='Random forest, observation '+str(i)) for o,i in zip(obs, (3,33,222))]

bd_lreg[0].plot(bd_lreg[1::])
#bd_boosting[0].plot(bd_boosting[1::])
bd_rf[0].plot(bd_rf[1::])

"""Shap waterfall plots"""

shap_explainer_rf = shap.explainers.Tree(rf_model, data=X_train)
shap_values_rf = shap_explainer_rf(X_train)

for i in [3,33,222]:
    shap.plots.waterfall(shap_values_rf[i])

"""4. find two observations in the data set, such that they have different variables of the highest importance."""

shap.plots.waterfall(shap_values_rf[1])
shap.plots.waterfall(shap_values_rf[14])

"""5. (if possible) select one variable and find two observations in the data set such that for one observation this variable has a positive effect and for the other a negative effect"""

shap.plots.waterfall(shap_values_rf[3])
shap.plots.waterfall(shap_values_rf[33])

y_train.iloc[3], y_train.iloc[33]

"""6. train a second model (of any class, neural nets, linear, other boosting) and find an observation for which BD/shap attributions are different between the models"""

masker = shap.maskers.Independent(data = X_train)
shap_explainer_lreg = shap.explainers.Linear(lreg_model, data=X_train, masker = masker)
shap_values_lreg = shap_explainer_lreg(X_train)

shap.plots.waterfall(shap_values_lreg[11])
shap.plots.waterfall(shap_values_rf[11])

!jupyter nbconvert --to=html drive/MyDrive/'Colab Notebooks'/XAI/AnnaSemik_HW2.ipynb

